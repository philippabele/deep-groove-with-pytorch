\documentclass[a4paper, 12pt, oneside]{scrbook}
\input{settings.tex}
\addbibresource{bibliography.bib}

\begin{document}
	\frontmatter
	\input{prefix/title.tex}
	\input{prefix/abbreviation.tex}
	\tableofcontents
	\listoffigures
	%\listoftables
	%\lstlistoflistings
	\nocite{*}

	\mainmatter

	\pagebreak
%	\conclusion
	\chapter{Introduction} 
	
	\chapter{Theoretical Basis}
	
		\section{Exploratory Data Analysis} \label{EDA}
			
			\noindent Frederik Hardwig describes Exploratory Data Analysis (\ac{EDA}) as two thinks. As a Way of Thinking and a Method to work with data. 
			The Data Miner should always keep in mind, that you need to look for new Patterns that weren't expected, because they are the most interesting. It is important not trying to proof your own Thesis from before the Analyzing Process but to find new ones and always keep open to new findings. Also the Data Analyst should be skeptic towards Methods that compromise Data. If Data is summarized there will always be some loss of Information and the Hypothesis that will be based on these results will be not complete. To avoid this it is a good thing being skeptic towards compressed data. 
			As a Method, \ac{EDA} works with a lot of visualization to find patterns in Datasets. It is important not to confuse Data Analysis and Statistics. It is important to keep in mind that even the most used statistical Methods could have some hidden assumptions about the data. It is always suggested to use diagrams and other visual methods to display data to minimize errors resulting out of these assumptions.\cite{Hardwig:Explortory_Data_Analysis}
			
			\noindent \ac{EDA} tries to generate a understanding of the data and not to proof already stated Hypothesis. This contrasts the Initial Data Analysis (\ac{IDA}) where it is more common to look closely for findings that are needed to develop a modal and testing hypothesis. The goals of \ac{EDA} is to develop and evaluate Hypothesis, provide recommendations for statistical Techniques to support the analyzing process and provide Methods to collect more Data. It tries to find relationships between elements and get the main features of the data. 
			
			\noindent To achieve these goals it uses different Methods. Descriptive Statistics is used to get a overview of the Data and the structure of the data. It is very important to get a feeling for the data structure to get the most meaningful and efficient results. In \ref{fig:statistical_description} we can see the main statistical characteristics of a dataset, witch contains the top female chess players in the world by the Rating in Standard Chess games. We can see the number of fields, that are filled (count), the median of the value(mean) and the standard deviation(std). It also shows us the Maximum (max) and minimum (min) and the higher, lower and middle quantil (25\%, 75\%, 50\%).
			
			\begin{figure} [H]
				\centering
				\resizebox{\linewidth} {!} {
					\includegraphics{res/df_describes.png}
					
				}
				\caption{statistical description of the data}
				\label{fig:statistical_description}
			\end{figure}
		
			\noindent To visualize these statistical Properties we can use a Box-Plot. In \ref{fig:boxplot} is the standard rating column of the data visualized. This method can also applied on all columns with a metric datatype. So we could do the same with the other rating fields and the year of birth, but the id doesn't make sense because it is an nominal field. 
			
			\begin{figure} [H]
				\centering
				\resizebox{\linewidth} {!} {
					\includegraphics{res/boxplot.png}
					
				}
				\caption{Box-Plot of the standard rating}
				\label{fig:boxplot}
			\end{figure}
		
			\noindent An other way to get more information over the data is to group it by nominal fields. In this example we can group the data by federation or title of the chess player. In \ref{fig:groupeby} are the median given grouped by the federation.
			
			\begin{figure} [H]
				\centering
				\resizebox{\linewidth} {!} {
					\includegraphics{res/groupby.png}
					
				}
				\caption{Group by the country and showing the median}
				\label{fig:groupeby}
			\end{figure}
			
			To explore the relationships of the fields in the data we need to reduce the dimensions of the data elements. in our case one element has  dimensions. The standard, rapid, blitz rating and also the players age. We need to dissect the four dimensions to two. To do this we plot every single field against every other in their own chart. These charts can be seen in \ref{fig:crosschart}. We can also add a fifth nominal field by coloring the data points according to the Title. The result of the chart matrix is symmetrical and the diagonal charts are the same values plotted against each other so we only need to look at one side of the matrix.
			
			\begin{figure} [H]
				\centering
				\resizebox{\linewidth} {!} {
					\includegraphics{res/crosschart.png}
					
				}
				\caption{Plotting every data field against each other}
				\label{fig:crosschart}
			\end{figure}
			
			\noindent Out of the Charts in \ref{fig:crosschart} we can also generate the linear Correlation of the fields. The closer to one or minus one the value is, the better the two fields correlate linear. So we can say that in our data, blitz and rapid rating correlate more linear than standard rating with the other both in our data. But there is more to think about in this assumption. The data shows only the Players with a standard rating above 1960 so there is a hard line in the data. This results in a incomplete model of reality and we need to include it into our result. 
			The hypothesis could be that the blitz and rapid ratings correlate linear, with a value of 0.878720, under the top Players with a standard rating above 1960.
			We cannot see non linear correlations in this matrix so we could oversee them.
			
			\begin{figure} [H]
				\centering
				\resizebox{\linewidth} {!} {
					\includegraphics{res/Correlation.png}
					
				}
				\caption{Correlation chart}
				\label{fig:correlation}
			\end{figure}
			
	\chapter{Application}
		\section{First Steps with a Dataset}
			\subsection{Exploratory Data Analysis}
			\noindent A dataset is provided with three values. It has data of an shaft-bearing-system loaded with rotational force and rotations per minute and a third value, which is the lifetime in hours.
			
			\begin{figure}[H]
				\centering
				\begin{minipage}[b]{0.4\textwidth}
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/df_info.png}
					}	
					\caption{df.info()}
					\label{fig:EDA_info}
				\end{minipage}
				\hfill
				\begin{minipage}[b]{0.4\textwidth}
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/df_head.png}
					}	
					\caption{First 5 Datapoints in the table}
					\label{fig:EDA_head}
				\end{minipage}
			\end{figure}
			
			\noindent After showing the info of the data and getting an general feel for the data set, we can see how the data points are related to each other with the same techniques from Chapter \ref{EDA}. We create a chart for every feature of a data point and get the charts in picture \ref{fig:EDA_crossplot}. the charts where we use \textit{Fr} and \textit{n} aren't correlated at all. In a more zoomed in we can se that the points are evenly distributed. This makes sense if the data is a systematic test, with the changing parameters of rotation n and radial Force Fr. In picture \ref{fig:EDA_3Dscatter} there is a 3D scatter of the data points with n and Fr on the x and y axis and the Lifetime on the z axis. It shows a better Picture of the data were the equal distributed points show a good visible plane. The lifetime increases rapidly when n and Fr go towards zero and shrink exponential when one of both parameters are increased.
	
			\begin{figure}[H]
				\centering
				\begin{minipage}[b]{1\textwidth}
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/crosschart.png}
					}	
					\caption{All Data fields plotted against each other}
					\label{fig:EDA_crossplot}
				\end{minipage}
				\hfill
				\begin{minipage}[b]{1\textwidth}
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/3dscatter.png}
					}
					\caption{3D scatter of the Data set}
					\label{fig:EDA_3Dscatter}
				\end{minipage}
			\end{figure}
			\subsection{first Machine Learning Model}
				\noindent After the analytic exploration of the data set, we can train our first machine learning model on the data. My goal is to use the Rotation n and the Force Fr as input and get the Years of Life as the output. For this we first need to load the data from the csv and create an feature data class out of it, with which the machine learning model can work with. For this I implemented the \texttt{FeatureDataclass} to hold the test and training data. In Picture \ref{fig:FeatureDataclass} is the Code for this class. In the Constructor of the class the given data frame is cut into the input and output values and saved into \texttt{self.sample} and \texttt{self.label}. Beside the Constructor also \texttt{\_\_len\_\_} and \texttt{\_\_getitem\_\_} is added. These methods return the length of the data set or the element at the given index.
				
				\begin{figure} [H]
					\centering
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/feature_dataset.png}
						
					}
					\caption{FeatureDataset class}
					\label{fig:FeatureDataclass}
				\end{figure}
				
				\noindent In the main class the Lifetime column in the data is classified into years. This is achieved by converting the hours to years and rounding down. After the data is as it need to be, two FeatureDataset object are created. One to train the model on and the other to test it. To feed the data to the model, it needs to get divided into small batches. Data loaders provide this functionality so one for the testing- and for the training data are created. I used a batch size of 10 after some testing because it fitted very well with the overall size of the data set.
				
				\noindent Before the training can start, a Model must be created. I decided I want to keep the Network simple so I only used two ReLU-Layers with 10 nodes each. The Input layer has two nodes, corresponding with the two input variables. The Export layer has 6 Nodes, each representing one class of the labels. In Picture \ref{fig:layer_first} the layers are shown. 
				
				\begin{figure} [H]
					\centering
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/layer_model.png}
						
					}
					\caption{Layers of the first machine learning model}
					\label{fig:layer_first}
				\end{figure}
			
				\noindent The parameters for this program is an learning rate of $1 * 10^{-7}$, the amount the model modifies its weights an biases. I tried different epochs, how often the optimization loop is done, and stick with 200 because it fits well with the learning rate. After all the parameters are set, the training can begin. 
				
				\noindent In every epoch the program does an training and a testing loop. In the training loop the model gets trained on the data. The model gets small batches of data from the data loader and optimizes its weights and biases every step using the optimizer function. In this case I use an cross entropy loss function. It uses the probability output of the model to determine a distance to the desired output and adjusts the weights in every iteration. This function is well suited to classification problems. After the model is trained, it gets tested on the testing data. Here the program does not modify its weights anymore and just computes an loss and an accuracy of the model. This Values describe the difference between the models prediction and the test data. The lower the loss, the better. The higher the accuracy, the better. 
				
				\noindent after all the epochs are done, the accuracy and loss values are plotted on a diagram using \texttt{matplotlib}. In Picture \ref{fig:lossAndAccuracy} these diagrams are shown after an training of 200 epochs.
				
				\begin{figure} [H]
					\centering
					\resizebox{\linewidth} {!} {
						\includegraphics{res/firstEDA/lossAndAccuracy.png}
						
					}
					\caption{Loss and Accuracy over 200 epochs}
					\label{fig:lossAndAccuracy}
				\end{figure}
	 
	\chapter{Implementation}
	
	
	\chapter{Summary} % Fazit
	
	\frontmatter
	\printbibliography
\end{document}
